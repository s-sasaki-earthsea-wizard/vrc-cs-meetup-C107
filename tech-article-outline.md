# AI VTuber開発に用いられている技術についての記事構成案

**タイトル**: Discord Botに個性を持たせる - RAGによるパーソナライズされたAI VTuber配信の実装

**推奨ページ数**: 14ページ
**想定読者**: AI/Bot技術に興味のある開発者、VTuber配信者、Discordコミュニティ運営者

---

## 1. はじめに（序論）（1ページ）

### 1.1 本記事の目的

- AI VTuberとRAGを組み合わせたパーソナライズシステムの紹介
- 従来のプロンプトエンジニアリングだけでは実現できない「個性」の実装
- オープンソースプロジェクトとして、誰でも試せる実装例の提供

### 1.2 想定読者

- AI/Bot技術に興味のある開発者
- VTuber配信を始めたい方
- Discordコミュニティを運営している方
- RAG（検索拡張生成）の実装例を探している方

### 1.3 記事の構成

簡単にこの記事の流れを説明します：

1. **第2章**: 実際の配信デモを見せます。何ができるのかを理解してもらいます
2. **第3章**: システム全体像とアーキテクチャを説明します
3. **第4章**: RAGによるパーソナライゼーションの実装（記事のコア）
4. **第5章**: VTuber配信への統合方法
5. **第6章**: 運用コストと実際の効果測定
6. **第7章**: まとめと今後の展望

---

## 2. AI VTuber配信デモ - 何ができるのか（2ページ）

### 2.1 実際の配信画面

**実際の配信の様子（スクリーンショット・動画リンク）**

このシステムの特徴：
- **VRMアバター**が自然な日本語で喋る
- **YouTube Liveチャット**から質問を受付
- **RAGによって知識やキャラクター設定に沿った応答**を生成（音声合成でリアルタイムに返答）

### 2.2 パーソナライズ応答の実例

#### 例1: 同じ質問、異なる応答

**ユーザーA（Discord発言履歴: "Factorio楽しい", "工場最適化が好き"）**
```
質問: "おすすめのゲーム教えて"

AI VTuber応答:
「Factorioが好きなら、Satisfactoryもおすすめだよ！
3D版Factorioみたいな感じで、工場最適化の楽しさはそのままに、
建築の自由度も高いんだ。きっと気に入ると思う！」

[過去発言から「Factorio」「工場最適化」を検索して応答に反映]
```

**ユーザーB（Discord発言履歴: "Apex楽しい", "FPS大好き"）**
```
質問: "おすすめのゲーム教えて"

AI VTuber応答:
「FPS好きなら、Valorantはどう？Apexとはちょっと違う戦術FPSで、
アビリティを使ったチーム戦が面白いよ。
Overwatch 2も無料だし試してみる価値あり！」

[過去発言から「Apex」「FPS」を検索して応答に反映]
```

→ **同じ質問でも、ユーザーごとに全く違う応答**

#### 例2: より深いパーソナライゼーション

**ユーザーC（Discord発言履歴: "Rust勉強中", "所有権システム難しい"）**
```
質問: "おすすめの技術書教えて"

AI VTuber応答:
「Rustやってるなら『プログラミングRust 第2版』がおすすめ！
所有権システムの章が特に詳しくて、理解が深まると思うよ。
あとは『Rustで始めるネットワークプログラミング』も
実践的で面白いよ。」
```

**パーソナライズなしの場合**:
```
"『リーダブルコード』や『Clean Code』が人気ですよ！"
```

→ 明らかに個性が出ている

---

## 3. システム全体像 - どう動いているか（2.5ページ）

### 3.1 キャラクター設定の課題と解決策

#### AI VTuberのキャラクター定義の課題

AI VTuberを作る際、最初に当たる壁が「**キャラクターをどう設定するか？**」という問題です。

一般的なRAGシステムでは、技術ドキュメントやFAQなど、既に存在する静的な知識ベースを使います。しかし、AI VTuberの場合、その「個性」や「記憶」をどう定義するかが課題です。

**従来の手法の限界**:
- システムプロンプトに長々とキャラクター設定を書き込む → 限界があり、不自然
- 全会話履歴をプロンプトに含める → コスト高、文脈長超過
- ファインチューニング → 更新困難、コスト大

#### 解決策: Discordを日記帳として活用

本プロジェクトでは「**Discordに自分の日記用サーバーを立てて、そこのレコードを活用する**」という手法を採用しました。

日常的に自分の経験や考えをDiscordに書いておくと、自然にナレッジが溜まっていく。実際、筆者は真実と真実を元にしたフィクションを半分半分くらいで書いています。「宝塚歌劇が好き」「ポケモンのダブルバトルが好き」「プラズマ物理を研究している」といった断片的な情報を、日常会話のように記録していく。

**最も重要なポイント**: Discordの書き込みをDBに登録する仕組みを作ったので、**Discordに書き込めば勝手にDBの知識が増えていく**のです。

**メリット**:
- ✅ キャラクター設定の更新が容易: Discordに書き込むだけ
- ✅ 自然な記憶の蓄積: 日記を書くような感覚でAIの「記憶」が成長
- ✅ メンテナンスコストの削減: JSONファイルを手動編集する必要がない

現在、筆者のナレッジDBには**124件**のレコードが蓄積されています（2025年11月時点）。

### 3.2 システムアーキテクチャ

#### フロー全体像

**Discord発言収集からYouTube Live配信までの流れ**（図3.1参照）

1. **Discord書き込み** → 自動収集（DB起動時に更新）
2. **ベクトル化** → OpenAI Embeddings API（1536次元）
3. **ナレッジDB保存** → PostgreSQL + pgvector
4. **YouTube Live配信** → 視聴者からの質問
5. **RAG検索** → 関連する過去発言を取得
6. **LLM応答生成** → パーソナライズされた応答
7. **TTS音声合成** → VRMアバターが喋る

### 3.3 技術スタック

**本プロジェクトはAIRIプロジェクト[^airi]をフォークして開発しました。**

[^airi]: AIRI - https://github.com/moeru-ai/airi

AIRIには既にVRMアバター表示、TTS音声合成、リップシンク、ナレッジDB基盤が実装されており、これらを活用することで開発期間を大幅に短縮できました。詳細はAIRI公式ドキュメントを参照してください。

#### 本プロジェクトで追加した技術

**YouTube Live統合**:

- **YouTube Data API v3**: ライブチャット取得
- ポーリング方式で10秒ごとにチャット取得
- WebSocket経由でstage-webに配信

**メッセージキュー**: TTS再生中の会話重複を防止

**アイドルトーク**: ユーザー入力がない時に自発的に話す機能

#### AIRIから継承した技術

**データベース・検索**:

- **PostgreSQL 17** + **pgvector (v0.4.0)**: ベクトル検索
- **Drizzle ORM**: 型安全なデータベース操作
- **HNSW インデックス**: 高速近似最近傍探索

**AI/ML**:

- **LLM**: OpenRouter経由（Claude 3.5 Sonnet推奨）
- **Embeddings**: OpenAI text-embedding-3-small (1536次元)
- **TTS**: ElevenLabs, Azure, Google等のマルチプロバイダー対応

**VTuber配信**:

- **VRM**: 3Dアバター表示（Three.js + @pixiv/three-vrm）
- **wlipsync**: 音声駆動リップシンク
- **OBS**: Browser Sourceで配信画面に表示

### 3.4 既存インフラの活用

**重要な設計判断**: 新規テーブル作成せず既存を活用

AIRI本体の`memory_fragments`テーブルを流用：

- 元々はTelegram Botの会話記憶用
- `metadata`フィールド（JSONB）でプラットフォーム判別可能
- 複数のベクトル次元に対応済み

```typescript
// packages/telegram-bot/src/db/schema.ts (既存)
export const memoryFragmentsTable = pgTable('memory_fragments', {
  id: uuid().primaryKey(),
  content: text().notNull(),
  category: text().notNull(),  // 'tech', 'hobby', 'game'等
  metadata: jsonb().default({}), // { source: 'discord', authorId: '...' }
  content_vector_1536: vector({ dimensions: 1536 }),
  // ...
})
```

→ 開発期間短縮、インフラ構築不要

---

## 4. RAG検索の工夫と課題解決（4ページ）

### 4.1 ベクトル検索の限界 - 「北斗の拳問題」（1ページ）

#### 単純なベクトル検索の失敗例

開発初期、類似度スコアのみでRAG検索を実装したところ、以下のような問題が発生しました：

**質問**: "好きな動物は？"

**期待される検索結果**:
```
「実家には犬がいて、よく散歩に連れて行っていた」
```

**実際の検索結果**（類似度順）:
```
1. [46.2%] 北斗の拳が好き！トキとかケンシロウとか... ← ❌ 無関係だが類似度高い
2. [45.9%] ポケモンのダブルバトルが面白い ← △ 微妙（架空の生き物）
3. [42.2%] 実家には犬がいて、よく散歩に連れて行っていた ← ✅ 本命だが3位
```

**問題**: 「北斗の拳」（トキ、ケン等のキャラクター名）や「ポケモン」（架空の生き物）の方が、実際のペットである「犬」よりも類似度が高くなってしまう

**原因**:

- 「動物」「好き」という抽象的なクエリでベクトル化
- Embeddingsモデルは文脈を考慮せず、単語の意味的近さのみでスコア化
- 架空の生き物も「動物」カテゴリとして認識される

**この問題を「北斗の拳問題」と名付けました**

#### なぜ単純な類似度だけでは不十分なのか

ベクトル検索（セマンティック検索）は、キーワード検索と比べて以下の点で優れています：

- ✅ 形態素解析不要
- ✅ 同義語に対応（"マイクラ" = "Minecraft"）
- ✅ 意味的な関連性を捉える
- ✅ 多言語対応

しかし、以下の課題があります：

- ❌ 文脈を考慮しない（架空 vs 現実の区別がつかない）
- ❌ ユーザーの意図を理解できない（ペットの話を聞きたいのか、キャラクターの話を聞きたいのか）
- ❌ 類似度スコアの絶対値に意味がない（0.78と0.68の差が重要かは文脈次第）

### 4.2 解決策: 3段階検索パイプライン（2ページ）← **記事のコア**

#### 段階1: LLMによるクエリ拡張

**課題**: 「好きな動物は？」だけでは、具体的な動物名が検索に含まれない

**解決**: LLM（Gemini 2.0 Flash Lite）で質問を具体的なキーワードに展開

**プロンプト設計の工夫**:

重要なのは「具体的な固有名詞やカテゴリ名を優先する」よう指示すること：

```markdown
次の質問から、ベクトル検索に有効な具体的なキーワードを抽出してください。

## 重要な指示

### 1. 具体的な固有名詞やカテゴリ名を優先してください
- 良い例: 「犬」「猫」「ゲーム」「アニメ」
- 悪い例: 「好き」「興味」「関心」「楽しみ」

### 2. 抽象的な類義語や汎用的すぎる言葉は避けてください

### 3. 表記ゆれを含めてください
- 例: 「犬」「イヌ」
```

**実行結果**:

```text
質問: "好きな動物は？"
↓
展開されたキーワード: ["動物", "犬", "イヌ", "猫", "ネコ", "鳥", "魚", "ペット"]
```

**効果**: 具体的な動物名で検索することで、「犬」に関する発言がヒットしやすくなる

**JSONモードの活用**:

確実にキーワードを抽出するため、OpenAI互換のJSON Modeを使用：

```json
{
  "type": "json_schema",
  "json_schema": {
    "name": "keyword_extraction",
    "schema": {
      "type": "object",
      "properties": {
        "keywords": { "type": "array", "items": { "type": "string" } }
      },
      "required": ["keywords"]
    }
  }
}
```

#### 段階2: 緩和された閾値でのベクトル検索

**従来の閾値**: 0.7（関連性が高いもののみ）

**新しい閾値**: 0.25（候補を多めに収集）

**理由**:

- クエリ拡張により検索範囲が広がるため、閾値を下げても問題ない
- 次の段階（リランキング）で精度を担保するため、まずは候補を多く集める

**実行結果**:

```text
展開キーワード: ["動物", "犬", "イヌ", "猫", "ネコ", "鳥", "魚", "ペット"]

各キーワードでベクトル検索（閾値0.25）:
- "犬" → 15件ヒット
- "猫" → 8件ヒット
- "ペット" → 12件ヒット
... (合計50件の候補)
```

**重複除外**: IDでユニークな結果のみを保持

#### 段階3: LLMによるリランキング

**課題**: 50件の候補から、質問に最も関連するものを選ぶ

**解決**: LLM（Claude 3.5 Sonnet）で候補を評価し、Top-Kを選択

**プロンプト例**:

```text
質問: "好きな動物は？"

以下の候補から、この質問に最も関連する発言を選んでください。

候補:
1. 「実家には犬がいて、よく散歩に連れて行っていた」
2. 「北斗の拳が好き！トキとかケンシロウとか...」
3. 「ポケモンのダブルバトルが面白い」
...

重要:
- 実際のペット・動物の話題を優先してください
- 架空の生き物やキャラクターは除外してください
```

**実行結果**:

```text
リランキング後のTop-3:
1. 「実家には犬がいて、よく散歩に連れて行っていた」 ← 正解！
2. 「猫カフェに行ったことがある」
3. 「鳥のさえずりが好き」

除外されたもの:
- 「北斗の拳が好き！トキとかケンシロウとか...」
- 「ポケモンのダブルバトルが面白い」
```

**効果**: 文脈を理解したLLMが、ユーザーの意図に沿った結果を選択

#### パフォーマンス測定

| 段階 | 処理時間 | コスト |
|------|---------|--------|
| クエリ拡張（Gemini 2.0 Flash Lite） | 200ms | $0.00002 |
| ベクトル検索（50件） | 50ms | - |
| リランキング（Claude 3.5 Sonnet） | 800ms | $0.001 |
| **合計** | **1,050ms** | **$0.00102** |

**トレードオフ**:

- ✅ 検索精度が大幅に向上（「北斗の拳問題」解決）
- ⚠️ レイテンシが約1秒増加（許容範囲内）
- ⚠️ コストが微増（1クエリあたり約0.1円）

### 4.3 実装での工夫（0.5ページ）

#### 工夫1: 話題の継続（反復的RAG検索）

第2章で紹介した通り、応答内容で再度検索することで話題を深掘り：

```text
「お芝居は好き？」
  ↓ 第1回検索
「宝塚歌劇が好き」
  ↓ 第2回検索（「宝塚」で再検索）
「はいからさんが通る」の舞台を観た
  ↓ 第3回検索（「はいからさんが通る」で再検索）
紅緒さんへの憧れ、大正時代への興味
```

**実装**: `excludeIds`パラメータで既出の知識を除外し、話題を広げる

#### 工夫2: アイドルトーク時のナレッジDB検索スキップ

**課題**: アイドルトーク機能（自発的に話す機能）が発動すると、その内部プロンプトでもナレッジDB検索が走ってしまい、意図しない知識が注入される

**解決**: グローバルフラグ `isCurrentlyIdleTalking` で制御

```typescript
// アイドルトーク中はナレッジDB検索をスキップ
if (isCurrentlyIdleTalking.value) {
  console.info('[index.vue] Skipping Knowledge DB query (idle talk in progress)')
  return
}
```

#### 工夫3: 環境変数のlocalStorage上書き

**課題**: VueのuseLocalStorageがブラウザのlocalStorageにキャッシュするため、.envファイルを変更してもLLMモデルやTTS設定が更新されない

**解決**: 起動時に強制的にlocalStorageを上書き

```typescript
// 環境変数を優先させる
localStorage.setItem('settings/consciousness/active-model', llmModel)
localStorage.setItem('settings/speech/active-provider', ttsProvider)
```

---

## 5. YouTube Live統合とOBS配信（1ページ）

### 5.1 YouTube Live統合

#### YouTube Data API v3でチャット取得

**ポーリングベースの実装**:
```typescript
// 10秒ごとにライブチャットをポーリング
setInterval(async () => {
  const response = await youtube.liveChatMessages.list({
    liveChatId: liveChatId,
    part: ['snippet', 'authorDetails'],
    maxResults: 50
  })

  for (const message of response.data.items) {
    // RAG検索 → LLM応答生成
    await handleMessage(message)
  }
}, 10000)
```

**APIクォータ管理**:
- YouTube Data API v3: 1日10,000ユニット
- `liveChatMessages.list`: 約5ユニット/リクエスト
- 10秒間隔: 約8,640リクエスト/日 → 約43,200ユニット必要
- **課題**: デフォルトクォータでは不足
- **対策**: 適応的ポーリング（活発時は短く、非活動時は長く）

### 5.2 OBS統合

#### OBS Browser Sourceでの表示

**設定手順**:
1. stage-webをローカルで起動（`http://localhost:5173`）
2. OBSで「Browser」ソースを追加
3. URLに`http://localhost:5173`を設定
4. 解像度: 1920x1080（フルHD）
5. カスタムCSS（オプション）:
   ```css
   body { background-color: rgba(0, 0, 0, 0); }
   ```
   → 背景を透過

**配信レイアウト例**:
```
┌──────────────────────────────────┐
│ OBS 配信画面                      │
├──────────────────────────────────┤
│                                  │
│  ┌────────────┐                 │
│  │ VRMアバター │  ← Browser Source
│  │ (stage-web)│                 │
│  └────────────┘                 │
│                                  │
│  チャット欄 (YouTube Live)       │
│  ┌──────────────────────┐       │
│  │ viewer: おすすめは？  │       │
│  │ AI: Factorioなら...  │       │
│  └──────────────────────┘       │
└──────────────────────────────────┘
```

---

## 6. 運用コストと効果測定（1.5ページ）

### 6.1 効果測定

#### パーソナライズあり vs なし

**テストケース**:
```
ユーザー: "疲れた時のリフレッシュ法は？"

【パーソナライズなし】
"散歩や音楽鑑賞がおすすめです。"

【パーソナライズあり（過去発言: ゲーム好き、音楽好き）】
"軽めのゲームやるのはどう？マイクラで無心に整地とか、
Factorioの工場を眺めるだけでも癒されるよね。
あとはロック聴きながらコーヒー飲むとか。
The Clashの『London Calling』とかどう？"
```

**ユーザー満足度**（非公式フィードバック）:
- パーソナライズなし: "普通のBot"
- パーソナライズあり: "自分のこと分かってくれてる感じ"

### 6.2 運用コスト

#### コスト総括

| 項目 | 月額コスト | 備考 |
|------|-----------|------|
| LLM (Claude 3.5) | 約$5 | 月10配信、50応答/配信 |
| **TTS (ElevenLabs)** | **$22** | **最大コスト**<br>Creator plan<br>40分配信=6,000クレジット<br>100,000クレジット/月 |
| Embeddings | $0.01 | OpenAI<br>誤差レベル |
| インフラ | $0-10 | PostgreSQL Dockerローカル実行なら無料 |
| **総コスト** | **約$32-42/月**<br>（約5,000円） | 配信頻度による |

**実測値（ElevenLabs TTS）**:
- 40分の配信で約6,000クレジット消費
- 100,000クレジットで約11時間分の配信が可能
- 週1回1時間配信: 月4回 = 24,000クレジット → Creator planでカバー可能

**コスト削減案**:
- TTS: VOICEVOX（無料）、OpenAI TTS（$15/100万文字）
- LLM: Gemini Flash（無料枠）、Ollama（ローカル）

### 6.3 課題と対策

#### 課題1: プライバシーへの配慮

**対策**:
1. **オプトアウト機能**: `/privacy delete`でデータ削除
2. **データ保持期間**: 180日以上前のデータは自動削除
3. **センシティブ情報フィルタ**: 電話番号、メールアドレス等を除外

#### 課題2: 検索精度のばらつき

**対策**: ユーザーの過去発言が少ない場合、コミュニティ全体から補完

---

## 7. まとめと今後の展望（1ページ）

### 7.1 成果

#### 技術的成果
- **低コスト**: 月額約5,000円で運用可能
- **高精度**: ベクトル検索で意味的類似性を捉える
- **自動化**: メッセージ収集からカテゴリ分類まで全自動
- **スケーラブル**: HNSWインデックスで10万件でも高速

#### RAGの有効性
- LLMの文脈長制限を回避
- トークン消費を最小化（コスト削減）
- ユーザーごとのパーソナライズ実現
- 既存インフラ（memory_fragments）を活用

#### AI VTuber配信の実現
- YouTube Live統合
- VRMアバター + TTS でリアルな配信
- ユーザーごとに異なる応答で個性を演出

### 7.2 応用可能性

**他プラットフォームへの展開**:
- Twitch配信
- LINE Bot
- Slack Bot
- Matrix Bot

**他用途への応用**:
- カスタマーサポート（FAQ自動応答）
- 教育Bot（学習者の理解度に応じた説明）
- コミュニティ運営（サーバー全体の知識ベース）

### 7.3 今後の展望

#### 短期（3ヶ月）
- ユーザープロファイルの自動生成
- 画像・動画の分析（マルチモーダル）

#### 中期（6ヶ月）
- 時系列での興味変化の追跡
- コミュニティ全体の知識ベース構築

#### 長期（1年）
- 他のAI VTuberプロジェクトとの連携
- オープンソースコミュニティの拡大

### 7.4 オープンソースとして

- **GitHubで公開**: MIT Licenseで自由に利用可能
- **詳細なドキュメント**: セットアップから運用まで
- **コミュニティ駆動**: Issue、PRを歓迎

---

## 参考資料

### GitHubリポジトリ
- **本プロジェクト**: https://github.com/s-sasaki-earthsea-wizard/airi-youtube-live
- **元プロジェクト（AIRI）**: https://github.com/moeru-ai/airi

### 技術ドキュメント
- PostgreSQL pgvector: https://github.com/pgvector/pgvector
- OpenAI Embeddings API: https://platform.openai.com/docs/guides/embeddings
- Discord.js: https://discord.js.org/
- YouTube Data API v3: https://developers.google.com/youtube/v3

### 参考文献
- RAG (Retrieval-Augmented Generation): https://arxiv.org/abs/2005.11401
- HNSW Algorithm: https://arxiv.org/abs/1603.09320

---

**執筆日**: 2025年11月
**ライセンス**: MIT License
**プロジェクト**: AIRI YouTube Live Edition
